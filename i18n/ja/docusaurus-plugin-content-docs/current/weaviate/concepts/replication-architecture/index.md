---
title: レプリケーション アーキテクチャ
sidebar_position: 0
description: "高可用性・信頼性・データベース性能向上を実現する、マルチノードのデータレプリケーション設計。"
image: og/docs/concepts.jpg
# tags: ['architecture']
---

:::info Added in `v1.17`
:::

Weaviate は、[replication factor](../../manage-collections/multi-node-setup.mdx#replication-settings) を 1 より大きく設定することで、マルチノード クラスター間のデータレプリケーションを実現します。これにより、[高可用性](./motivation.md#high-availability-redundancy) など、さまざまな[利点](./motivation.md)が得られます。データベースのレプリケーションは、信頼性・スケーラビリティ・パフォーマンスを向上させます。

Weaviate では複数のレプリケーション方式を採用しています。

- [クラスター メタデータのレプリケーション](./consistency.md#cluster-metadata) は [Raft](https://raft.github.io/) コンセンサス アルゴリズムによって管理されます。
- [データレプリケーション](./consistency.md#data-objects) は [チューナブル](./consistency.md) かつリーダーレスです。

<details>
  <summary>クラスター <code>metadata</code> とは？</summary>

Weaviate クラスターの `metadata` には、コレクション定義やテナントのアクティビティ ステータスが含まれます。
<br/>

すべてのクラスター メタデータは、replication factor に関係なく常に全ノードにレプリケートされます。
<br/>

これは、オブジェクトの作成時刻などのオブジェクト メタデータとは異なります。オブジェクト メタデータは、指定された replication factor に従いオブジェクト データと一緒に保存されます。

</details>

この「レプリケーション アーキテクチャ」セクションでは、次の情報を提供します。

* **General Concepts**（本ページ）
  * レプリケーションとは？
  * CAP 定理
  * Weaviate にレプリケーションが必要な理由
  * レプリケーションとシャーディングの違い
  * Weaviate におけるレプリケーションの仕組み
  * ロードマップ


* **[Use Cases](./motivation.md)**
  * モチベーション
  * 高可用性
  * 読み取りスループット向上
  * ゼロダウンタイム アップグレード
  * リージョナル近接性


* **[Philosophy](./philosophy.md)**
  * 典型的な Weaviate のユースケース
  * リーダーレス アーキテクチャを選んだ理由
  * 段階的ロールアウト
  * 大規模テスト


* **[Cluster Architecture](./cluster-architecture.md)**
  * リーダーレス設計
  * Replication Factor
  * 書き込み・読み取り操作


* **[Consistency](./consistency.md)**
  * クラスター メタデータ
  * データオブジェクト
  * 修復


* **[Multi-DataCenter](./multi-dc.md)**
  * リージョナル近接性

## レプリケーションとは？

<p align="center"><img src="/img/docs/replication-architecture/replication-rf3-c-QUORUM.png" alt="Example setup with replication" width="75%"/></p>

データベース レプリケーションとは、同じデータポイントのコピーをクラスター内の複数ノードに保持することを指します。

その結果として得られるシステムは分散データベースです。分散データベースは複数ノードで構成され、それぞれがデータのコピーを保持できます。そのため、あるノード（サーバー）がダウンしても、ユーザーは別のノードからデータにアクセスできます。さらに、レプリケーションによりクエリ スループットも向上します。

## CAP 定理

レプリケーション導入の主目的は信頼性の向上です。[Eric Brewer](https://en.wikipedia.org/wiki/Eric_Brewer_(scientist)) は、分散データベースの信頼性には制限があることを [CAP 定理](https://en.wikipedia.org/wiki/CAP_theorem) で示しました。CAP 定理によれば、分散データベースは次の 3 つの保証のうち 2 つしか同時に提供できません。
* **Consistency (C)** - すべての読み取りが最新の書き込み、またはエラーを返し、全ノードが同一のデータを同時に参照できることを保証します。
* **Availability (A)** - すべてのリクエストに対し常にエラーのない応答を返しますが、最新の書き込みを含む保証はありません。
* **Partition tolerance (P)** - ノード間でネットワークにより任意のメッセージが失われたり遅延したりしても、システムが動作を継続できることを意味します。

<p align="center"><img src="/img/docs/replication-architecture/repliction-cap.png" alt="CAP Theorem" width="60%"/></p>

理想的には、Weaviate のようなデータベースが最高の信頼性を持つことが望まれますが、これは一貫性・可用性・パーティション耐性間のトレードオフによって制限されます。

### 一貫性と可用性のトレードオフ

:::tip
Consistency (C)、Availability (A)、Partition tolerance (P) のうち、同時に保証できるのは 2 つだけです。

Partition tolerance が必須であるとすると、残りの 2 つのうちシステムにとって重要な方を選択する必要があります。
:::

一貫性・可用性・パーティション耐性のうち、同時に保証できるのは 2 つだけです。クラスターは分散システムであり、ネットワーク パーティションが発生する前提のため、設計の際には **一貫性 (C)** か **可用性 (A)** のいずれかを選択することになります。

**一貫性** を可用性より優先すると、ネットワーク パーティションによりデータが最新であることを保証できない場合、データベースはエラーやタイムアウトを返します。**可用性** を一貫性より優先すると、データベースは常にクエリを処理し、最新である保証がなくても可能な限り最新のデータを返そうとします。

C を A より優先すべき典型例は、トランザクションを扱う銀行口座データなどのクリティカル データベースです。取引データでは、常に一貫性がなければ残高が正しくなくなる可能性があります。

一方、重要度が低いデータベースでは、A を C より優先できます。例としてメッセージング サービスが挙げられます。多少古いデータが表示されても許容されますが、高可用性と低レイテンシーで大量の書き込みを処理する必要があります。

Weaviate は一般的に後者の設計に従います。多くの場合、Weaviate はクリティカル データよりも比較的重要度の低いデータを扱い、近似検索のセカンダリ データベースとして利用されるためです。詳細は [Philosophy](./philosophy.md) を参照してください。ただし、必要に応じて Weaviate の [チューナブル コンシステンシー](./consistency.md#tunable-consistency-strategies) を利用できます。

## Weaviate にレプリケーションが必要な理由

Weaviate はデータベースとして、ユーザーのリクエストに対し信頼できる応答を提供しなければなりません。前述のとおり、データベースの信頼性にはさまざまな要素があります。以下は、Weaviate でレプリケーションが望ましいユースケースです。詳細は [Replication Use Cases (Motivation)](./motivation.md) をご覧ください。

1. **高可用性（冗長性）**<br/>
   分散（レプリケートされた）データベース構成では、1 台のサーバーノードがダウンしてもサービスは中断されません。データベースは引き続き利用可能で、読み取りクエリは利用可能なノードに（ほぼ気付かれずに）リダイレクトされます。  
2. **読み取りスループットの向上**<br/>
   データベース構成にサーバーノードを追加すると、スループットも比例して増加します。ノードが多いほど、システムが処理できるユーザー（読み取り操作）数が増えます。コンシステンシー レベル `ONE` で読み取りを行う場合、replication factor（すなわちノード数）を増やすとスループットは線形に向上します。  
3. **ゼロダウンタイム アップグレード**<br/>
   レプリケーションがない場合、Weaviate インスタンスをアップグレードする際にダウンタイムが発生します。単一ノードを停止・更新・再起動して再び利用可能になるまでサービスは停止します。レプリケーションがあればローリング アップデートが可能になり、常に最大でも 1 ノードのみが停止し、他のノードがトラフィックを継続的に処理します。  
4. **リージョナル近接性**<br/>
   ユーザーが異なる地域（例：アイスランドとオーストラリア）にいる場合、データベース サーバーとの物理的距離によりすべてのユーザーに低レイテンシーを保証できません。分散データベースを使用すると、異なるローカル地域にノードを配置してレイテンシーを削減できます。これはレプリケーションの Multi-Datacenter 機能に依存します。
## レプリケーションとシャーディング

レプリケーションは [シャーディング](../cluster.md) とは異なります。シャーディングは水平スケーリングを指し、Weaviate には v1.8 で導入されました。

* **レプリケーション** はデータを別々のサーバーノードにコピーします。Weaviate では、これによりデータの可用性が向上し、単一ノードが障害を起こした場合の冗長性が確保されます。クエリスループットもレプリケーションによって改善できます。
* **シャーディング** はデータを分割し、その断片（シャード）を複数のレプリカセットに送ることで、サーバー間の水平スケーリングを行います。データは分割され、すべてのシャードを合わせると完全なデータセットになります。Weaviate でシャーディングを使用すると、大規模データセットの運用やインポート速度の向上が可能です。

<p align="center"><img src="/img/docs/replication-architecture/replication-replication-vs-sharding.png" alt="レプリケーションとシャーディング" width="60%"/></p>

レプリケーションとシャーディングは組み合わせて使用でき、スループットと可用性を高めるとともに、インポート速度の向上や大規模データセットへの対応が可能になります。たとえば、データベースのレプリカ数を 3、シャード数を 3 に設定すると、合計 9 個のシャードが生成され、各サーバーノードが 3 つの異なるシャードを保持します。

## Weaviate でのレプリケーションの仕組み

### クラスタメタデータのレプリケーション

Weaviate のクラスタメタデータ変更は Raft によって管理され、クラスタ全体で一貫性を確保しています。（これにはコレクション定義やテナントのアクティブステータスが含まれます。）

Weaviate `v1.25` から、クラスタメタデータの変更は Raft コンセンサスアルゴリズムを使用してコミットされます。Raft はリーダーベースのコンセンサスアルゴリズムで、リーダーノードがクラスタメタデータの変更を担当します。Raft により、少数ノードの障害が発生しても変更内容はクラスタ全体で一貫性を保ちます。

<details>
  <summary>メタデータレプリケーション（<code>v1.25</code> 以前）</summary>

Weaviate `v1.25` 以前では、各クラスタメタデータの変更は 2 フェーズコミットを用いた分散トランザクションで記録されていました。
<br/>

これは同期プロセスであり、すべてのノードが変更を認証して初めてコミットされます。このアーキテクチャでは、ノードがダウンするとメタデータ操作が一時的に停止します。さらに、一度に処理できる操作は 1 件のみでした。

Weaviate `v1.24` 以前をお使いの場合は、クラスタメタデータ変更に Raft コンセンサスアルゴリズムを利用するために [ `v1.25` へのアップグレード](/deploy/migration/weaviate-1-25.md) をご検討ください。

</details>

### データレプリケーション

Weaviate では、一般的に一貫性よりも可用性を優先します。データレプリケーションにはリーダーレス設計を採用しており、プライマリやセカンダリの概念はありません。データの読み書き時、クライアントは 1 つ以上のノードに接続します。ユーザーとノードの間にはロードバランサーがあり、ユーザーはどのノードと通信しているかを意識する必要がありません（ユーザーが誤ったノードにリクエストしても Weaviate が内部で転送します）。

読み書き（v1.18 以降）で確認応答が必要なノード数は `ONE`、`QUORUM`（n/2+1）、`ALL` に設定できます。書き込み操作で整合性レベルを `ALL` にすると、データベースは同期的に動作します。`ALL` 以外に設定した場合（v1.18 以降）、ユーザー視点では非同期で書き込みが行われます。

レプリカ数はノード数（クラスタサイズ）と一致している必要はありません。Weaviate ではコレクション単位でデータを分割することが可能です。これは [シャーディングとは異なります](#replication-vs-sharding)。

レプリケーションの詳細は [Philosophy](./philosophy.md)、[Cluster Architecture](./cluster-architecture.md)、[Consistency](./consistency.md) をご覧ください。

## Weaviate でレプリケーションを利用するには

[レプリケーションの設定方法](/deploy/configuration/replication.md) を参照してください。コレクション定義でレプリケーションを有効化できます。クエリでは、[希望する整合性レベルを指定](../../search/basics.md#replication) できます。

## ロードマップ

* 未定
  * マルチデータセンターレプリケーション（この機能への投票は [こちら](https://github.com/weaviate/weaviate/issues/2436)）

## 関連ページ
- [Configuration: Replication](/deploy/configuration/replication.md)

## ご質問・フィードバック

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>