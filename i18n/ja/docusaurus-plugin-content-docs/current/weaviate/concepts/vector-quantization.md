---
title: 圧縮（ベクトル量子化）
sidebar_position: 19
description: "メモリ フットプリントを削減しつつ検索速度を向上させるベクトル圧縮技術。"
image: og/docs/concepts.jpg
# tags: ['vector compression', 'quantization']
---

**ベクトル量子化** は、[vector index](./indexing/vector-index.md) に格納されるベクトル埋め込みを圧縮することでメモリ フットプリントを削減し、デプロイ コストを抑えながらベクトル類似度検索の速度を向上させます。

Weaviate では現在、以下の 4 つのベクトル量子化手法を提供しています。

- [バイナリ量子化 (BQ)](#binary-quantization)
- [直積量子化 (PQ)](#product-quantization)
- [スカラー量子化 (SQ)](#scalar-quantization)
- [回転量子化 (RQ)](#rotational-quantization)

## 量子化

一般に量子化技術は、数値をより低い精度で表現することでメモリ フットプリントを削減します。たとえば数値を最も近い整数に丸めるような操作です。ニューラル ネットワークでは、モデルの重みや活性化を 32 ビット浮動小数点数（4 バイト）から 8 ビット整数（1 バイト）などの低精度数値に変換してメモリを節約します。

### ベクトル量子化

ベクトル量子化は、ベクトル埋め込み自体のメモリ フットプリントを削減する技術です。ベクトル埋め込みは通常 32 ビット浮動小数点数で表現されますが、量子化によって 8 ビット整数やバイナリ数などの小さな数値で表現できます。手法によってはベクトルの次元数も削減されます。

## 直積量子化

[Product quantization](https://ieeexplore.ieee.org/document/5432202) は、Weaviate の `hnsw` インデックスで使用できる多段階の量子化手法です。

PQ は各ベクトル埋め込みを 2 段階で小さくします。まずベクトル次元をより小さな「セグメント」に分割し、その後各セグメントを元のビット数（通常 32 ビット float）より少ないビット数に量子化します。

import PQTradeoffs from '/_includes/configuration/pq-compression/tradeoffs.mdx' ;

<PQTradeoffs />

PQ では、元のベクトル埋め込みを複数の小さなベクトル（セグメントまたはサブスペース）に分割し、それらを直積として表現します。その後、各セグメントを独立に量子化して圧縮ベクトルを生成します。

![PQ の概要図](./img/pq-illustrated.png "PQ の概要図")

セグメント作成後、`centroids` を計算するためのトレーニング ステップがあります。既定では各セグメントを 256 個のセントロイドにクラスタリングし、これらのセントロイドによってコードブックを生成します。以降の圧縮処理では、このコードブック内で最も近いセントロイドの ID を用いて各ベクトル セグメントを表現します。

たとえば、各ベクトルが 768 要素（各 4 バイト）のコレクションを考えます。PQ 圧縮前は 1 ベクトルにつき `768 × 4 = 3 072` バイト必要ですが、圧縮後は `128 × 1 = 128` バイトで済みます。元の表現は PQ 圧縮版のほぼ 24 倍のサイズです（コードブックのわずかなオーバーヘッドは除く）。

PQ を有効化する方法は [Enable PQ compression](/weaviate/configuration/compression/pq-compression#enable-pq-compression) を参照してください。

### セグメント

`segments` パラメーターはメモリ使用量とリコールのトレードオフを制御します。値を大きくするとメモリ使用量とリコールが向上します。なお、セグメント数は元のベクトル次元数を割り切れる必要があります。

代表的なベクトライザー モジュールで利用可能なセグメント値は次のとおりです。

| モジュール      | モデル                                   | 次元数 | セグメント数                     |
|-----------------|------------------------------------------|--------|----------------------------------|
| openai          | text-embedding-ada-002                  | 1 536  | 512, 384, 256, 192, 96           |
| cohere          | multilingual-22-12                      | 768    | 384, 256, 192, 96                |
| huggingface     | sentence-transformers/all-MiniLM-L12-v2 | 384    | 192, 128, 96                     |

### PQ 圧縮プロセス

PQ にはコードブックを生成するトレーニング ステージがあります。シャードごとに 10 000 ～ 100 000 件のレコードでのトレーニングを推奨します。トレーニングは手動または自動で起動できます。詳細は [Configuration: Product quantization](../configuration/compression/pq-compression.md) を参照してください。

トレーニングが開始されるとバックグラウンド ジョブがインデックスを圧縮インデックスへ変換します。変換中はインデックスが読み取り専用となり、完了するとシャードのステータスが `READY` に戻ります。

Weaviate はトレーニングに `trainingLimit` 件まで（シャードごと）のオブジェクトしか使用しません。対象数が多くても上限で切り捨てます。

変換完了後は通常どおり検索や書き込みが行えます。ただし量子化の影響で距離がわずかに変化する場合があります。

:::info どのオブジェクトがトレーニングに使われますか？
- (`v1.27` 以降) コレクション内のオブジェクト数がトレーニング上限を超える場合、Weaviate はランダムにサンプリングしてコードブックを学習します。
    - (`v1.26` 以前) コレクションの先頭から `trainingLimit` 件を使用します。
- コレクションのオブジェクト数がトレーニング上限未満の場合は、すべてのオブジェクトを使用します。
:::

### エンコーダー

上記設定では `encoder` オブジェクトでセントロイド生成方法を指定できます。既定の `kmeans` は従来の手法です。

実験的な `tile` エンコーダーも利用可能です。SIFT や GIST などのデータセットで高速インポートと高いリコールを示しています。`tile` にはセントロイド生成時の `distribution` パラメーターがあります。`type` を `tile` または `kmeans` に設定してエンコーダーを選択してください。設定詳細は [Configuration: Vector index](../config-refs/indexing/vector-index.mdx) を参照してください。

### 距離計算

Product quantization では問い合わせベクトルは非圧縮のまま保持し、非対称的に距離計算を行います。これにより精度を保ちながら計算量を削減します。

:::tip
Weaviate での product quantization の設定方法は [こちら](../configuration/compression/pq-compression.md) をご覧ください。<br/><br/>
ブログ記事「[How to Reduce Memory Requirements by up to 90%+ using Product Quantization](https://weaviate.io/blog/pq-rescoring)」も参考になります。
:::

## バイナリ量子化

**Binary quantization (BQ)** は各ベクトル埋め込みをバイナリ表現へ変換する量子化手法です。通常 1 次元あたり 32 ビットを要しますが、バイナリ表現では 1 ビットで済むため、ストレージ要求を 32 倍削減できます。その結果、ディスクから読み込むデータ量が減少し、距離計算も簡素化されるため検索速度が向上します。

代償として BQ はロスの大きい手法です。バイナリ表現では情報が大幅に失われるため、距離計算の精度は元のベクトル埋め込みより低下します。

ベクトライザーによって BQ との相性は異なります。経験的には Cohere の V3 モデル（例: `embed-multilingual-v3.0`、`embed-english-v3.0`）や OpenAI の `ada-002` モデルで良好なリコールを確認しています。ご自身のデータとベクトライザーでテストし、適合性をご判断ください。

BQ を有効にするとベクトル キャッシュを用いたクエリ性能向上が可能です。キャッシュは量子化済みベクトルのディスク読み込みを減らして検索を高速化しますが、各ベクトルが `n_dimensions` ビットを占有するためメモリ使用量とのバランスが必要です。

## スカラー量子化

**Scalar quantization (SQ)** では、ベクトル埋め込みの各次元を 32 ビット float から 8 ビット整数へ変換します。これによりサイズを 4 倍圧縮できます。

SQ も BQ と同様にロスのある圧縮ですが、表現範囲が大きく、精度が高い点が特徴です。データを分析して値域を決定し、その範囲を 256 個（8 ビット）のバケットに一様分割します。各次元の値は該当バケットの番号（8 ビット整数）で表現されます。

トレーニング セットのサイズは設定可能で、既定はシャードあたり 100 000 件です。

SQ が有効な場合、Weaviate は圧縮結果を多めに取得してからオリジナルの非圧縮ベクトルで再スコアリングし、リコールを向上させます。再検索は対象が少数のため高速です。

## 回転量子化

:::caution Technical preview

Rotational quantization (RQ) は **`v1.32`** で **技術プレビュー** として追加されました。<br/><br/>
今後のリリースで仕様変更や破壊的変更が発生する可能性があります。  
**本番環境での使用は現時点では推奨していません。**

:::

**Rotational quantization (RQ)** はトレーニング不要の 8 ビット量子化手法で、4 倍の圧縮率を保ちつつ多くのデータセットで 98–99 % のリコールを維持します。RQ はインデックス作成時にすぐ有効化でき、以下 2 ステップで動作します。

1. **高速疑似乱数回転**: 入力ベクトルに Walsh Hadamard Transform を利用した高速回転を適用します。1 536 次元ベクトルで約 7–10 µs です。出力次元は 64 の倍数へ切り上げられます。
2. **スカラー量子化**: 回転後の各エントリを 8 ビット整数に量子化します。各ベクトル個別の最小値と最大値が量子化区間を決定します。

回転ステップにより量子化区間が短縮され誤差が減少し、距離情報が均等に分散されます。

なお、次元数が 64 未満または 128 未満の低次元データでは、64 の倍数へ切り上げるため圧縮効率が最適でない可能性があります。

本実装は extended RaBitQ に着想を得ていますが、パフォーマンス上の理由で大きく異なります。真の乱数回転ではなく高速疑似乱数回転を用い、RaBitQ の符号化ではなくスカラー量子化を採用しています（ビット数が多い場合 RaBitQ は非常に遅くなるため）。

:::tip
Weaviate での回転量子化の設定方法は [こちら](../configuration/compression/rq-compression.md) をご覧ください。
:::

## 過剰フェッチ / リスコアリング

Weaviate は、 SQ、 RQ、 BQ を使用する場合に結果を過剰フェッチし、その後でリスコアリングを行います。これは、圧縮された ベクトル での距離計算が、元の ベクトル 埋め込みでの計算ほど正確ではないためです。

クエリを実行すると、 Weaviate はクエリの limit を設定可能な `rescoreLimit` パラメーターと比較します。

クエリは、いずれか大きいほうの上限に達するまで圧縮オブジェクトを取得します。その後、 Weaviate は圧縮 ベクトル に対応する元の非圧縮 ベクトル 埋め込みを取得し、それらを使ってクエリ距離スコアを再計算します。

たとえば、 limit が 10、 rescoreLimit が 200 のクエリの場合、 Weaviate は 200 件のオブジェクトを取得します。リスコアリング後、クエリは上位 10 件のオブジェクトを返します。このプロセスにより、圧縮によって発生する検索品質（リコール）の低下が補正されます。

:::note RQ 最適化
RQ のネイティブリコールは 98〜99% と高いため、多くの場合リスコアリングを無効化（ `rescoreLimit` を 0 に設定）しても、検索品質への影響を最小限に抑えながらクエリ性能を最大化できます。
:::

## ベクトルインデックスを用いたベクトル圧縮

### HNSW インデックスとの併用

[HNSW インデックス](./indexing/vector-index.md#hierarchical-navigable-small-world-hnsw-index) は、 [PQ](#product-quantization)、 [SQ](#scalar-quantization)、 [RQ](#rotational-quantization)、 [BQ](#binary-quantization) を使用して構成できます。HNSW はメモリ内インデックスであるため、圧縮によってメモリ使用量を削減したり、同じメモリ量でより多くのデータを保存したりできます。

:::tip
当社ブログ記事 [HNSW+PQ - Exploring ANN algorithms Part 2.1](https://weaviate.io/blog/ann-algorithms-hnsw-pq) もぜひご覧ください。
:::

### フラットインデックスとの併用

[BQ](#binary-quantization) は [フラットインデックス](./indexing/inverted-index.md) を使用できます。フラットインデックス検索はディスクから読み込むため、圧縮によって読み込むデータ量が減り、検索が高速化されます。

## リスコアリング

量子化では情報の精度が下がるため、必然的に情報損失が発生します。これを軽減するために、 Weaviate はリスコアリングと呼ばれる手法を用います。圧縮 ベクトル とともに保存されている非圧縮 ベクトル を使用し、初回検索で返された候補の元の ベクトル 間の距離を再計算します。これにより、最も正確な結果がユーザーに返されます。

場合によっては、リスコアリングが過剰フェッチも伴い、初回検索で上位候補が欠落しないよう追加の候補を取得します。

## 参考リソース

:::info Related pages
- [概念: インデックス化](./indexing/index.md)
- [概念: ベクトルインデックス](./indexing/vector-index.md)
- [設定: ベクトルインデックス](../config-refs/indexing/vector-index.mdx)
- [設定: スキーマ（意味インデックスの設定）](../config-refs/indexing/vector-index.mdx#configure-semantic-indexing)
- [設定方法: バイナリ量子化（圧縮）](../configuration/compression/bq-compression.md)
- [設定方法: 直積量子化（圧縮）](../configuration/compression/pq-compression.md)
- [設定方法: スカラー量子化（圧縮）](../configuration/compression/sq-compression.md)
- [設定方法: 回転量子化（圧縮）](../configuration/compression/rq-compression.md)
- [Weaviate Academy: 250 Vector Compression](../../academy/py/compression/index.md)
:::

## 質問とフィードバック

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>