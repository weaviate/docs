---
title: 要件の特定と候補モデルの収集
description: ニーズを特定し、候補モデルのリストを作成して、埋め込みモデル選定を始めましょう。
---

import ThemedImage from '@theme/ThemedImage';

## <i class="fa-solid fa-chalkboard-user"></i> ニーズの特定

体系的なモデル選定を行うには、まず要件を明確にすることが重要です。要件をカテゴリーごとに整理すると、埋め込みモデルを評価する際に関連する要素を漏れなく検討できます。

以下に主な検討ポイントを示します。

<img
    src={require('./_img/identify_needs_overview.png').default}
    alt="Identify your needs"
/>

### <i class="fa-solid fa-chalkboard"></i> データの特性

| 要素 | 主な質問 | 重要な理由 |
| --- | --- | --- |
| **モダリティ** | テキスト、画像、音声、それともマルチモーダル？ | モデルは特定のモダリティ向けに構築されています。 |
| **言語** | どの言語をサポートする必要がありますか？ | モデルは特定の言語向けに学習・最適化されており、性能にトレードオフが生じます。 |
| **ドメイン** | データは一般的か、それともドメイン特化（法律、医療、技術など）ですか？ | ドメイン特化モデル（例： [医療](https://huggingface.co/blog/abhinand/medembed-finetuned-embedding-models-for-medical-ir)）は専門用語や概念を理解できます。 |
| **長さ** | ドキュメントやクエリの平均的な長さは？ | 入力トークンのコンテキストウィンドウはモデルごとに異なり、 256 トークンから 8192 トークンまでさまざまです。ただし、長いコンテキストウィンドウは計算量と待ち時間が指数的に増加します。 |
| **非対称性** | クエリとドキュメントに大きな違いがありますか？ | 一部のモデルは非対称なクエリ‐ドキュメント比較向けに設計されています。たとえば `laptop won't turn on` というクエリで `Troubleshooting Power Issues: If your device fails to boot...` のようなドキュメントを容易に特定できます。 |

### <i class="fa-solid fa-chalkboard"></i> パフォーマンス要件

| 要素 | 主な質問 | 重要な理由 |
| --- | --- | --- |
| **精度**（リコール） | 上位結果をすべて取得することはどれほど重要ですか？ | 高い精度を求める場合、より高価またはリソース集約的なモデルを選択する価値があります。 |
| **レイテンシ** | クエリはどれくらい速く処理する必要がありますか？ | 大規模モデルは性能が高い一方で推論が遅くなることがあります。推論サービスでは、高速化はコスト増につながります。 |
| **スループット** | 想定クエリ量やトラフィックスパイクは？ | 大規模モデルは処理能力が低い傾向があります。推論サービスではスループット増加がコスト増加を招きます。 |
| **ボリューム** | 処理するドキュメント数は？ | 埋め込み次元が大きいほどベクトルストアのメモリ要件が増え、大規模運用時のリソースとコストに影響します。 |
| **タスクタイプ** | 検索のみか、それともクラスタリングや分類も行いますか？ | モデルには得意不得意があります。検索に優れたモデルがクラスタリングでも優秀とは限りません。評価・選定基準に影響します。 |

### <i class="fa-solid fa-chalkboard"></i> 運用上の要素

| 要素 | 主な質問 | 重要な理由 |
| --- | --- | --- |
| **ハードウェア制限** | ホスティング・推論に利用可能な計算資源は？ | ハードウェアの入手性（コスト、GPU/TPU の有無）が選択肢に大きく影響します。 |
| **API レート制限** | ホステッドモデルの場合、プロバイダーの制限は？ | レート制限はアプリケーションのボトルネックや成長の妨げになります。 |
| **デプロイと保守** | 必要な技術的専門知識とリソースは？ | 自前ホスティングが可能か、API ベースのホステッドオプションを検討すべきかを判断します。 |

### <i class="fa-solid fa-chalkboard"></i> ビジネス要件

| 要素 | 主な質問 | 重要な理由 |
| --- | --- | --- |
| **ホスティングオプション** | 自前ホスティングが必要か、クラウド API でもよいか？ | 自前ホスティング ➡️ 操作性は高いが運用が複雑、API ➡️ 導入は簡単だが依存度が高い。 |
| **ライセンス** | 商用利用時のライセンス制限は？ | 一部のモデルは特定のユースケースを禁止しています。 |
| **長期サポート** | モデルの継続利用に関する保証は？ | モデルや企業が廃止された場合、アプリケーションの大幅な改修が必要になることがあります。 |
| **予算** | コスト上限や支出方針は？ | 埋め込みコストは継続的に発生しますが、自前ホスティングは初期費用が高額です。 |
| **プライバシーとコンプライアンス** | データプライバシー要件や業界規制は？ | 特定業界では専用モデルが必須となり、プライバシー要件がホスティング手段を制限する場合があります。 |

これらの要件を文書化すると、理想的な埋め込みモデルの明確なプロファイルが作成され、選定プロセスで情報に基づくトレードオフを行いやすくなります。

## <i class="fa-solid fa-chalkboard-user"></i> 候補モデルの収集

ニーズを特定したら、評価対象となる埋め込みモデルのリストを作成します。この作業により、詳細評価を有望な候補に絞り込めます。

現在、埋め込みモデルは数百種類あり、日々新しいモデルが発表されています。これだけ多くのモデルを単純なスクリーニングでさえ評価するのは時間がかかりすぎます。

そのため、次のような簡単なヒューリスティックを使って、まず初期リストを絞り込むことをお勧めします。

### <i class="fa-solid fa-chalkboard"></i> モダリティで絞り込む

これは最初に行うべき重要なフィルターです。モデルは設計・学習されたモダリティのみをサポートします。

たとえば Cohere の `embed-english-v3.0` はマルチモーダルですが、Snowflake の `snowflake-arctic-embed-l-v2.0` は単一モダリティです。

どれほど優れたモデルでも、 `snowflake-arctic-embed-l-v2.0` のようなテキスト専用モデルでは画像検索はできません。同様に `ColQwen` モデルはプレーンテキスト検索には使えません。

### <i class="fa-solid fa-chalkboard"></i> すでに利用可能なモデルを優先する

組織内で他のアプリケーションに埋め込みモデルを既に使用している場合、それらは優れた出発点になります。既に審査・評価・承認され、アカウントや請求も設定済みである可能性が高いからです。ローカルモデルの場合、インフラも整っているはずです。

これは他のサービスプロバイダー経由で利用できるモデルにも当てはまります。

たとえば Cohere、Mistral、OpenAI などのプロバイダーを通じて生成 AI モデルを既に使用している場合があります。また AWS、Microsoft Azure、Google Cloud などのハイパースケーラーが埋め込みモデルを提供していることもあります。

多くの場合、これらのプロバイダーから埋め込みモデルにもアクセスできるため、新しい組織のモデルより採用しやすいでしょう。

### <i class="fa-solid fa-chalkboard"></i> 有名モデルを試す

一般に、よく知られたモデルが人気なのには理由があります。

Alibaba、Cohere、Google、NVIDIA、OpenAI などの AI 業界のリーダー企業は、さまざまなモダリティ、言語、サイズの埋め込みモデルを提供しています。以下は各社の代表的なモデルファミリーです。

| プロバイダー | モデルファミリー |
| --- | --- |
| Alibaba | `gte`, `Qwen` |
| Cohere | `embed-english`, `embed-multilingual` |
| Google | `gemini-embedding`, `text-embedding` |
| NVIDIA | `NV-embed` |
| OpenAI | `text-embedding`, `ada` |

他にも検討できるファミリーがあります。

たとえば、画像埋め込み用の `ColPali` ファミリー、マルチモーダル（画像とテキスト）向けの `CLIP` / `SigLIP` ファミリーが有名です。また `nomic`, `snowflake-arctic`, `MiniLM`, `bge` は言語検索モデルの代表例です。

これらの人気モデルはドキュメントや情報交換が豊富で、サポートも広く提供されています。

そのため、あまり知られていないモデルよりも導入・評価・トラブルシュートが容易です。

### <i class="fa-solid fa-chalkboard"></i> ベンチマーク上位モデル

標準ベンチマークで優れた性能を示すモデルも検討する価値があります。 [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) などのリソースで高性能モデルを確認できます。

以下のスクリーンショットは、 1 billion 未満のパラメータで `retrieval` 性能順に並べた MTEB の例です。

<img
    src={require('./_img/mteb_by_retrieval.png').default}
    alt="MTEB example - sorted by retrieval performance"
/>

ここには既に紹介した `snowflake-arctic`、Alibaba の `gte`、BAAI の `bge` などのモデルが含まれています。

加えて、Microsoft Research の `intfloat/multilingual-e5-large-instruct` や JinaAI の `jinaai/jina-embeddings-v3` など、まだ紹介していない高性能モデルも簡単に見つかります。

2025 年時点で、MTEB には言語やモダリティの要件を評価する複数のベンチマークが含まれています。

ベンチマークを見る際は、適切なベンチマークセットと列を確認してください。以下の例では、画像検索用の MIEB で *Any to Any Retrieval* 列を基準にソートしています。

<img
    src={require('./_img/mieb_by_any_to_any.png').default}
    alt="MIEB example - sorted by any to any retrieval"
/>

MTEB はさまざまな指標でフィルタリングやソートができます。好みに合わせて並べ替え、リストにモデルを追加してください。

これらの手法を用いれば、短時間で扱いやすいモデルリストを作成できるはずです。このリストを手動で精査し、詳細なスクリーニングへと進みましょう。
## 質問とフィードバック

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>