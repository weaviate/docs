---
title: 初期スクリーニングの実施
description: 入手可能な情報を利用してモデル一覧を絞り込む
---

import ThemedImage from '@theme/ThemedImage';

## <i class="fa-solid fa-chalkboard-user"></i> 概要

候補モデルのリストを適切なサイズ（最大で 10-20 件程度）まで絞り込めたら、手動でのレビューを開始できます。

この段階では、まとめた要件を利用可能なモデルの詳細と照らし合わせてスクリーニングを行います。多くの場合、公開モデルにはモデルカードやドキュメント、関連論文などを通じて概要情報が提供されています。

<img
    src={require('./_img/model_cards.png').default}
    alt="モデルカード"
/>

すぐに確認できる要素と、そのチェック方法を以下に示します。

## <i class="fa-solid fa-chalkboard-user"></i> スクリーニング要素

### <i class="fa-solid fa-chalkboard"></i> コンテキスト長

入力コンテキスト長は、ドキュメントのチャンク全体の意味を考慮できるかどうかを左右する重要な要素です。最大入力コンテキスト長はモデルによって大きく異なります。例を挙げると次のとおりです。

- `all-MiniLM-L6-v2`: 256 トークン
- Cohere `embed-english-v3.0`: 512 トークン
- `snowflake-arctic-embed-l-v2.0`: 8192 トークン

コンテキスト長を超える入力テキストは無視されます。一方、許容コンテキスト長が長くなるほど計算量とレイテンシは指数関数的に増加するのが一般的です。そのため、この点はテキストのチャンク化戦略とも相互に影響し合う重要なトレードオフとなります。

:::tip
ご自身のユースケースで取得したい「チャンク」がどの程度の大きさかを検討してください。一般的には 512 トークン以上のモデルであれば、ほとんどのユースケースで十分です。
:::

### <i class="fa-solid fa-chalkboard"></i> モデルの目的と学習方法論

各種埋め込みモデルはそれぞれ異なるユースケースに最適化されています。これはモデルアーキテクチャ、学習データ、学習手法の設計に反映されています。

モデル提供者が公開している説明や学習過程の詳細を確認すると、そのモデルがユースケースに適しているかどうかを判断するうえで重要な手掛かりになります。

- **言語対応能力**: Snowflake の `snowflake-arctic-embed-l-v2.0` のように多言語に対応しているモデルもあれば、Cohere の `embed-english-v3.0` のように主に単一言語に対応しているモデルもあります。これらの言語能力は主に学習データと手法の選択に由来します。
- **ドメイン露出**: 専門ドメイン（法務、医療、金融など）で学習されたモデルは、ドメイン固有のアプリケーションで一般に高い性能を発揮します。
- **主なタスク**: プロバイダーによっては汎用埋め込みモデルを提供している場合もあれば、特定タスクに特化したモデルを提供している場合もあります。Google の `gemini-embedding` モデルは、あらゆるタスクとドメインで最先端性能を目指す万能型モデルとして設計されているようです（[リリースブログ](https://developers.googleblog.com/en/gemini-embedding-text-model-now-available-gemini-api/)）。一方、Snowflake の `arctic-embed` 2.0 モデルは検索タスクに焦点を当てています（[リリースブログ](https://www.snowflake.com/en/engineering-blog/snowflake-arctic-embed-2-multilingual/)）。
- **ベースモデル**: 多くの場合、埋め込みモデルは既存モデルを元にして学習されます。元のモデルが持つ利点や欠点、とくにコンテキストウィンドウサイズやプーリング戦略といったアーキテクチャ上の特徴は、最終モデルにも引き継がれることがよくあります。
- **学習手法（上級）**: モデルの学習技術について知識がある場合は、これもヒューリスティックとして役立ちます。たとえば、コントラスト学習で訓練されたモデルは検索タスクで高性能を示すことが多いです。さらに、ハードネガティブマイニングはコントラスト学習を強化する有用なテクニックです。

:::tip
目標に合致した能力を持つモデルを選びましょう。たとえば、アプリケーションで英語・フランス語・ドイツ語・中国語・日本語のテキストチャンクを検索する必要がある場合は、モデルカードと学習情報を確認し、検索性能や学習コーパスにこれらの言語が含まれているかをチェックしてください。
:::

### <i class="fa-solid fa-chalkboard"></i> 次元数と最適化オプション

埋め込みの次元数は、性能とリソース要件の両方に影響します。

経験則として、ベクトルデータベースに必要なメモリ量（量子化を考慮しない場合）は、`4 bytes` × `n dimensions` × `m objects` × `1.5` となります。ここで、`m` はデータベース内オブジェクト数、`n` はベクトルの次元数で、`1.5` はオーバーヘッドを見込んでいます。

つまり、1,000 万オブジェクトの場合、各モデルのフル出力を保存するには次のメモリが必要になります。

- NVIDIA `NV-embed-v2`: `246 GB`
- OpenAI `text-embedding-3-large`: `184 GB`
- `snowflake-arctic-embed-l-v2.0`: `61 GB`
- `all-MiniLM-L6-v2`: `23 GB`

ご想像のとおり、これはベクトルデータベースのインフラコストを大幅に押し上げる可能性があります。

データベース側には、フットプリントとコストを削減するための量子化戦略が存在しますが、これについては別のコースで取り上げます。

しかし、モデル側でこの問題を緩和できる場合もあります。Matryoshka Representation Learning (MRL) に基づく `jina-embeddings-v2` や `snowflake-arctic-embed-l-v2.0` などのモデルは、ベクトルを途中で切り詰めるだけで柔軟に次元数を削減できます。たとえば `snowflake-arctic-embed-l-v2.0` では、元の 1024 次元を 256 次元まで削減しても、性能の損失はわずかです。

:::tip
データセットが将来的にどれくらいの規模になるかを想定し、それに見合うモデルを選定してください。システム要件が大きくなり過ぎて予算を超えるようであれば、本番環境へのスケールアップ時に振り出しに戻る恐れがあります。
:::

### <i class="fa-solid fa-chalkboard"></i> モデルサイズと推論速度

モデルサイズは推論速度に直接影響し、レイテンシ要件のあるアプリケーションでは極めて重要です。一般に、大きなモデルほど高性能ですが、その分計算負荷も増大します。

モデルをスクリーニングするときは、次の観点を考慮してください。

| 要素 | 影響 |
| --- | --- |
| パラメータ数 | パラメータが多いほど一般に品質は向上しますが、推論が遅くなりメモリ使用量が増えます |
| アーキテクチャ効率 | 一部のモデルはサイズが大きくても高速推論に最適化されています |
| ハードウェア要件 | 大規模モデルは GPU や TPU といった専用ハードウェアを必要とする場合があります |

:::tip
推論速度はモデルそのもの、推論用ハードウェア、さらにネットワークレイテンシの関数で決まります。モデルの適合性を評価するときは、これらをシステム全体として確認しましょう。
:::

### <i class="fa-solid fa-chalkboard"></i> 価格、可用性、ライセンス

モデルを採用する際の実務的な側面は、技術的要件を超えて多岐にわたります。

プロバイダーはさまざまな料金体系を提供しています。

- **API ベースの料金体系**: 1 トークンあたり課金 (OpenAI, Cohere)
- **コンピュートベースの料金体系**: ハードウェア使用量に応じて課金 (クラウドプロバイダー)
- **階層型ライセンス**: 価格に応じて機能・性能が異なる
- **オープンソース**: 無料で利用できますが、セルフホスティングのコストが発生します

モデルと推論形態の選択は、モデルの可用性にも影響します。

- **地理的可用性**: 一部のプロバイダーはすべての地域でサービスを提供していません
- **SLA 保証**: 稼働率のコミットメントおよびサポートレベル
- **レートリミット**: スループットの制限がアプリケーションに影響する可能性
- **バージョンの安定性**: モデルがどの程度の頻度で非推奨または更新されるか

さらに、ライセンス条項も大きく異なります。

- **商用利用制限**: 一部のオープンモデルは商用利用を禁止しています
- **データ使用ポリシー**: 提供者があなたのデータをどのように利用できるか
- **輸出規制**: 地域規制への準拠
- **デプロイ柔軟性**: オンプレミスやエッジデバイスへのデプロイが可能かどうか

必ず各モデルの具体的な利用条件を確認してください。たとえば、CLIP のようなモデルは公開されていますが、利用制限がアプリケーションに影響する場合があります。

:::tip
こうした実務的な要因は、性能上のメリットより重要になることもあります。ライセンス条件が良好でコストが低い、やや精度の劣るモデルのほうが、本番運用では好ましい場合があります。
:::
### <i class="fa-solid fa-chalkboard"></i> 候補ショートリストの作成

これらの要素を考慮した後、詳細に評価するモデルの優先ショートリストを作成できます。良いアプローチとして、次を組み合わせると効果的です。

1. **ベンチマーク上位**：標準メトリクスで高い性能を示すモデル  
2. **リソース効率の高いオプション**：フットプリントが小さい、または推論が高速なモデル  
3. **特化型モデル**：特定のドメインに特に適している可能性があるモデル  
4. **異なるアーキテクチャ**：多様なアプローチを含めることで、最適な適合を見つけられる可能性が高まります  

詳細な評価を行うために、初期ショートリストには 3～5 個のモデルを目安にしましょう。モデルが多すぎると、評価プロセスが扱いづらく時間もかかります。

次のセクションでは、これらの候補モデルを詳細に評価し、特定の要件を最も満たすモデルを決定する方法を説明します。

## 質問とフィードバック

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>