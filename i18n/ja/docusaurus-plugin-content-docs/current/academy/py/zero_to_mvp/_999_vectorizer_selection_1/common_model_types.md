---
title: 一般的なモデルタイプ
sidebar_position: 2
---

## <i class="fa-solid fa-square-chevron-right"></i> ベクトル表現の種類

:::warning TODO
イントロ動画はこちら
:::

ここでいうベクトルとは、通常、機械学習モデルから生成されたベクトルを指します。より具体的には、ニューラルネットワークから得られる「 dense ベクトル」と呼ばれるベクトルを指します。

しかし、特にテキストの意味を表す際には、他にも次のようなベクトル表現があります。

- One-hot encoding
- TF-IDF ( term frequency-inverse document frequency ) ベクトル
- BM25 ベクトル

以下では、これらと dense ベクトルについて簡単に説明します。

### One-hot encoding

One-hot encoding では、テキストを 0 と 1 の集合で表現し、1 はその単語がテキスト内に存在することを示します。これは「 bag of words 」表現とも呼ばれることがあります。

そのため、この表現は大部分が 0 になる非常にスパースなベクトルになります。これは、ほとんどの単語が特定のテキストには存在しないためです。

この方法の制限として、各単語は「存在する／しない」のみで表されるため、単語間の類似性を捉えられません。また、テキスト内での単語の相対的重要性を考慮できません。

### TF-IDF ベクトル

TF-IDF 表現は、テキスト内での単語の相対的重要性を考慮することで One-hot encoding を改良したものです。

TF-IDF は「 term frequency-inverse document frequency 」の略で、コーパス内の文書において単語がどれほど重要かを示す統計量です。

TF-IDF の値は、その単語が文書内に出現する回数に比例して増加しますが、コーパス全体での単語の出現頻度によって調整されます。これにより、"the"、"a"、"is"、"are" のような全文書で頻出する単語は減点され、全体でまれな単語に高い重みが付きます。

直感的には、TF-IDF はまれな単語により大きな重みを与えることで、テキスト内での単語の相対的重要性を捉えます。

### BM25 ベクトル

BM25 ベクトルは TF-IDF ベクトルに似ていますが、文書の長さを考慮できる点が異なります。長い文書は単語数が多くなるため、それだけで TF-IDF スコアが高くなる可能性がありますが、必ずしも短い文書より関連性が高いとは限りません。

そのため、BM25 ベクトルは文書の長さで TF-IDF スコアを正規化します。

### Dense ベクトル

#### Word ベクトル

Word ベクトルはニューラルネットワークから得られるベクトル表現の一種で、単語が現れる文脈を学習することで単語の意味を捉えます。

" word2vec " や " GloVe " といったモデルが、この種の表現学習を一般化しました。Word ベクトルの主な欠点は、親文のローカルな文脈、つまり文中での単語の使われ方を考慮できないことです。

そのため、同音異義語のように語義の判別が必要な場合、Word ベクトルは文脈内での単語の意味を捉えられません（たとえば "bank" が金融機関なのか川岸なのか）。

:::note Word vectors + weighting
Word ベクトルに TF-IDF や BM25 のような重み付け手法を組み合わせることで、テキスト内での単語の相対的重要性を反映したベクトルを生成できます。得られたベクトルはテキスト全体の表現として利用できます。
:::

#### Transformer 由来のベクトル

現在の多くのベクトルデータベースは、Transformer モデルから得られたベクトルを使用しています。

Transformer はニューラルネットワークの一種で、親文の文脈を考慮して単語の意味を決定します。これにより、前述の "bank" の例のように複数の意味を持つ単語を文脈に応じて判別できます。

現在の主な課題は、入力サイズ（例: テキスト長）が大きくなるにつれて計算資源を多く消費することです。

<Quiz questions={sparseOrDense} />

<Quiz questions={wordVecVsTransformer} />

## <i class="fa-solid fa-square-chevron-right"></i> メディアタイプ別

## <i class="fa-solid fa-square-chevron-right"></i> テキストベクトライザーの種類

## <i class="fa-solid fa-square-chevron-right"></i> マルチメディアベクトライザー

import Quiz from '/src/components/Academy/quiz.js'
const sparseOrDense = [
  {
    questionText: 'From the folloowing, select the correct statement about sparse and dense vectors.',
    answerOptions: [
      { answerText: 'One-hot encoding & word vectors: sparse, Transformer-derived: dense.', isCorrect: false, feedback: 'Word vectors are not sparse.'},
      { answerText: 'Document vector generated from BM25-weighted word vectors: sparse.', isCorrect: false, feedback: 'Word vectors are dense. Accordingly, a document vector generated by weighting BM25 scores are also dense.'},
      { answerText: 'One-hot encoding: sparse, TF-IDF based bag of words: dense.', isCorrect: false, feedback: 'Bag-of-words vectors are sparse. Accordingly, a vector that is based on TF-IDF weighting is also sparse.'},
      { answerText: 'One-hot encoding: sparse, Word vectors & transformer-derived: dense.', isCorrect: true, feedback: 'This is the only correct answer.'},
    ],
  },
];
const wordVecVsTransformer = [
  {
    questionText: 'Select the correct statement.',
    answerOptions: [
      { answerText: 'One-hot encoding & word vectors: sparse, Transformer-derived: dense.', isCorrect: false, feedback: 'Word vectors are not sparse.'},
      { answerText: 'Document vector generated from BM25-weighted word vectors: sparse.', isCorrect: false, feedback: 'Word vectors are dense. Accordingly, a document vector generated by weighting BM25 scores are also dense.'},
      { answerText: 'One-hot encoding: sparse, TF-IDF based bag of words: dense.', isCorrect: false, feedback: 'Bag-of-words vectors are sparse. Accordingly, a vector that is based on TF-IDF weighting is also sparse.'},
      { answerText: 'One-hot encoding: sparse, Word vectors & transformer-derived: dense.', isCorrect: true, feedback: 'This is the only correct answer.'},
    ],
  },
];